---
id: openai
title: OpenAI
---

:::info[`provider_slug`: `openai`]
:::

The `OpenAI` provider includes processors that correspond to [models from OpenAI](https://platform.openai.com/docs/models/overview).

## ChatGPT with Vision

:::info[`processor_slug`: `chatgpt_vision`]
:::

### Input

- `system_message`: A message from the system, which will be prepended to the messages.
- `messages`: A list of messages that you want to send to the ChatGPT.

### Configuration

- `model`: The ChatGPT model to use. Currently supports gpt-3.5-turbo and gpt-4.
- `max_tokens`: The maximum number of tokens allowed for the generated answer.
- `temperature`: The sampling temperature to use for generating responses.
- `retain_history`: Whether to retain and use the chat history.
- `auto_prune_chat_history`: Automatically prune chat history if retaining.

### Output

- `result`: The model generated response.

## ChatGPT

:::info[`processor_slug`: `chatgpt`]
:::

### Input

- `system_message`: A message from the system, which will be prepended to the chat history.
- `chat_history`: A list of messages, each with a role (user, assistant, system) and message text.
- `messages`: A list of new messages that you want to send to the ChatGPT.
- `functions`: A list of functions the model may generate JSON inputs for.

### Configuration

- `model`: The ChatGPT model to use.
- `max_tokens`: The maximum number of tokens allowed for the generated answer.
- `temperature`: The sampling temperature to use for generating responses.
- `n`: How many completions to generate for each prompt.
- `retain_history`: Whether to retain and use the chat history.
- `auto_prune_chat_history`: Automatically prune chat history if retaining.
- `stream`: Stream responses from the model (must be set to True).
- `function_call`: Controls how the model responds to function calls.

### Output

- `choices`: A list of messages generated by the ChatGPT model, each with a role and message content.

## Completions

:::info[`processor_slug`: `completions`]
:::

### Input

- `prompt`: The prompt to ask the OpenAI Completions model.

### Configuration

`datasources`: List of datasource UUIDs to use to retrieve data from the vector store for the asked question. If not provided, it will not provide any context to the OpenAI Completions model.

- `model`: OpenAI Completions model to use.
- `max_tokens`: Maximum number of tokens to generate in the completion.
- `temperature`: Sampling temperature to use, between 0 and 2. Higher values will make the output more random, while lower values will make it more focused and deterministic.

- `n`: How many completions to generate for each prompt.
- `stream`: Whether to stream the completions back to the client.
- `logit_bias`: Optional dictionary of logit biases to apply to the language model.

### Output

- `text`: The generated text from the OpenAI Completions model.

## Image generation

:::info[`processor_slug`: `image_generations`]
:::

### Input

- `prompt` (string, required): A text description of the desired image(s). The maximum length is 1000 characters.

### Configuration

- `model` (string): OpenAI Image generation model to use.
- `size` (string, optional): The size of the generated image in pixels. Must be one of 256x256, 512x512, or 1024x1024. The default size is 1024x1024. For example: "1024x1024."
- `n` (integer, optional): The number of images to generate. Must be between 1 and 10. The default value is 1. For example: 1.

### Output

- `images`: An array of generated images as base64 encoded strings.

## Image variation

:::info[`processor_slug`: `image_variations`]
:::

### Input

- `image`: The base64 encoded image to generate variations of.
- `image_data`: The base64 encoded data of the image, in case the image is not provided. This should follow the pattern: data:(mime_type);name=(file_name);base64,(base64_encoded_data).

### Configuration

- `size`: The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024.
- `n`: The number of images to generate. Must be between 1 and 10.

### Output

- `images`: An array of generated image variations as base64 encoded strings.

## Image edit

:::info[`processor_slug`: `images_edit`]
:::

### Input

- `image`: The base64 encoded image to edit. Must be a valid PNG file, less than 4MB, and square. If a mask is not provided, the image must have transparency, which will be used as the mask.
- `image_data`: The base64 encoded data of the image, in case the image is not provided. This should follow the pattern: data:(mime_type);name=(file_name);base64,(base64_encoded_data).
- `prompt`: The prompt to generate the edited image.

### Configuration

- `size`: The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024.
- `n`: The number of images to generate. Must be between 1 and 10.

### Output

- `image`: The edited image as a base64 encoded string.

## Audio transcription

:::info[`processor_slug`: `audio_transcriptions`]
:::

### Input

- `audio_file`: The audio file to transcribe.

### Configuration

- `model`: ID of the model to use. Only `whisper-1` is currently available.

### Output

- `transcript`: The transcribed audio as a string.

## Audio translation

:::info[`processor_slug`: `audio_translations`]
:::

### Input

- `file`: The audio file to translate, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.
- `prompt` (optional): An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.

### Configuration

- `model`: The ID of the OpenAI Audio translation model to use. Only `whisper-1` is currently available.

### Output

- `text`: The translated text.

## Text to Speech

:::info[`processor_slug`: `text_to_speech`]
:::

### Input

- `input_text`: The text to convert to speech.

### Configuration

- `model`: The ID of the OpenAI Text to Speech model to use.
- `voice`: The voice to use for the generated audio.
- `respones_format`: The format of the response. Can be `mp3`, `opus`, `aac` or `flac`.
- `speed`: The speed of the generated audio.
